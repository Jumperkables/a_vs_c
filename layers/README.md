# Models
The models developed for the associative vs categorical multimodal learning paradigm. The recently-updated [pytorch hopfield layers](https://github.com/ml-jku/hopfield-layers) kindly and ingeniously provided by the authors, are used in our models.<br>

**Variations of each model are included in here. Move them to the same locations as the other model files for each of the 3 tasks**
* `tvqa_avsc.py` -> `a_vs_c/tvqa/tvqa_modality_bias/model`
* `pvse_avsc.py` -> `a_vs_c/pvse`
* `avsd_avsc.py` -> `a_vs_c/avsd` **MAYBE CHANGE IF PUT IN encoder or decoder FOLDER**

### hopfield_layers:
The [officially provided pytorch GitHub repo for Hopfield Layers](https://github.com/ml-jku/hopfield-layers)

### assoc_vs_ctgrl.py:
A test file for me to experiment with Hopfield nets

